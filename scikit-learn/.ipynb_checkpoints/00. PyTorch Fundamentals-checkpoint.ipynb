{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663b73ad-5c40-4d2f-9b70-12d6803ad921",
   "metadata": {},
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bfb6cc-0238-4182-b627-aac4901b36fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f7d-c68b-465d-add2-b5f7feb504b1",
   "metadata": {},
   "source": [
    "# Introduction to tensors\n",
    "\n",
    "Tensors are the fundamental buidling block of machine learning.\n",
    "Their job is to represent data in a numerical way.\n",
    "\n",
    "EX: A tensor with shape [3, 224, 224] can be [color_channels, height, width], as in the image has 3 color channels(RGB), a height of 224 pixels and a width of 224 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403405aa-1a04-437c-98c2-455fca6dbde4",
   "metadata": {},
   "source": [
    "### Creating tensors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385c69de-f0c5-44cb-9971-1d9f440f585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar=torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d115911-7584-49f6-8df9-04d6672355f2",
   "metadata": {},
   "source": [
    "Chek the dimensions of a tensor using the ndim attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f36f5d-09bc-4f3f-bcfb-138fa62abec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e3ca2-9ae1-4cf9-b186-2ec917f4a594",
   "metadata": {},
   "source": [
    "Retrieve the number from the tensor using the item() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4250adda-ea7b-4d62-9372-d9d44710b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b94b36a-90c6-4737-8a44-a09eea31032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector=torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006f319b-6228-45d8-b474-01172ab47648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d746e-d29f-4659-aef2-10a8e4845f91",
   "metadata": {},
   "source": [
    "Another important concept for tensors is their shape attribute. The shape tells you how the elements inside them are arranged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7689682-ce26-427b-afe2-783e9ac7ce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e8fbc-3b27-4865-9787-49024c6e6c48",
   "metadata": {},
   "source": [
    "This is because of the two elements we placed inside the square brackets([7, 7])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16ee370-5770-4e4d-91ef-78551daff7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX=torch.tensor([[7,8],\n",
    "                    [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc218c5e-757d-4480-a5ae-941cbb1d51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4596e30-39eb-47dc-ab2b-c7f9deffb707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fbfe42a-9732-48ea-8bc7-48d02844f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR=torch.tensor([[[1,2,3],\n",
    "                      [3,6,9],\n",
    "                      [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a2b6c0-c9dd-49a0-8175-b8f54dc81976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "135c5758-6d31-453a-9810-2f4323a06aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fa14d-00b2-4b17-89b1-9615831dab98",
   "metadata": {},
   "source": [
    "# Random tensors\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2c34e56-ff58-4d19-a004-d55684763df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7509, 0.7032, 0.7231, 0.9522],\n",
       "         [0.5418, 0.7809, 0.6418, 0.5614],\n",
       "         [0.7069, 0.8804, 0.4428, 0.9607]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fddc12d8-aa93-4178-9f18-4c4a2f3f2a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor=torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e90f7-43a0-4ffb-917c-12ad93b273bb",
   "metadata": {},
   "source": [
    "# torch.zeros and torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9536cb4-255a-4d01-9b41-db1ea5571e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros=torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1818381-edaa-4326-8386-568e6c26e19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones=torch.ones(size=(3,4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804e394-e415-4938-bca0-9c12bf128661",
   "metadata": {},
   "source": [
    "# Creating a range and tensors like\n",
    "You can use torch.arange(start, end, step) to do so.\n",
    "\n",
    "Note: In Python, you can use range() to create a range, by in PyTorch, torch.range() is deprecated and may show an error.future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a512b9c-b5af-41e7-97dc-96e7c5ac2a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2344\\709803459.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated=torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten_deprecated=torch.range(0,10)\n",
    "\n",
    "zero_to_ten=torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fadc9-7728-4f36-ad6a-2296343459c2",
   "metadata": {},
   "source": [
    "To do so, you can use \n",
    "torch.zeros_like(input)\n",
    "or\n",
    "torch.ones_like(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1e8758-0735-4548-ae63-e78268976700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros=torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1640cd0c-18c0-4014-a304-4c90941cd7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones=torch.ones_like(input=ten_zeros)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f2a4d-f6db-4780-8340-c2599810911c",
   "metadata": {},
   "source": [
    "# Tensor datatypes\n",
    "\n",
    "Lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluations metrics like accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e7c278c-7946-423a-8858-5d7e92791bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor=torch.tensor([3.0,6.0,9.0],\n",
    "                             dtype=None,\n",
    "                             device=None,\n",
    "                             requires_grad=False)\n",
    "float_32_tensor.shape, float_32_tensor.dtype,float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69206f3b-2b33-4f6b-b45b-4a991e404a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=torch.tensor([3.0,6.0,9.0],\n",
    "                             dtype=torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d318814-1914-409b-b91e-a33f971d2739",
   "metadata": {},
   "source": [
    "# Getting information from tensors\n",
    "shape, dtype, device are the most common attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f54769e-075e-4905-a039-7a7b95a2452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9631, 0.6861, 0.7462, 0.8314],\n",
      "        [0.9061, 0.5780, 0.6070, 0.5790],\n",
      "        [0.0933, 0.0433, 0.1751, 0.6185]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor=torch.rand(3,4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75feeea3-da4f-4d2a-9901-ecced4c74956",
   "metadata": {},
   "source": [
    "# Tensor operations\n",
    "\n",
    "Addition, Subtraction, Multiplication, Division, Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ced1ab1-76bc-4b33-9ade-f9e9a572a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.tensor([1,2,3])\n",
    "tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9004de11-b080-497c-a08c-ed41703f5067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e59d4aa-e668-48fb-b73d-9425db23b036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afdab7d7-c7a8-4b51-affb-4c18be741ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=tensor-10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4acaf54-7ceb-4399-99d7-2f56b6de0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=tensor+10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94299eda-61ef-45cc-bab9-e3e82fa1dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals to tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise muliplication\n",
    "print(tensor,\"*\",tensor)\n",
    "print(\"Equals to\",tensor*tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e7a58-a2b0-46e4-abd3-20409570d529",
   "metadata": {},
   "source": [
    "### Matrix multiplication( is all you need!)\n",
    "1. The inner dimensions must match\n",
    "2. The resulting matrix has the shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89386660-43f5-416a-beef-750bd87e7c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor=torch.tensor([1,2,3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4539f4a2-bf2c-47c3-95a9-7c09ed9af62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "print(tensor*tensor)\n",
    "print(tensor@tensor) # Not recommended\n",
    "print(torch.matmul(tensor,tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56561582-b4ed-45b7-9c85-def7d136c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3.86 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value=0\n",
    "for i in range(len(tensor)):\n",
    "    value+=tensor[i]*tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "665835be-70a4-44ee-b554-fba858613ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9248f-c974-4764-af59-31bd00b96d24",
   "metadata": {},
   "source": [
    "#### One of the most common errors in deep learning (shape erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e847ee3b-2b8c-4c87-b75a-082d08b2b4b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m A\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m B\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      5\u001b[0m                [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      6\u001b[0m                [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 7\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(A,B)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[1,2],\n",
    "               [3,4],\n",
    "               [5,6]], dtype=torch.float32)\n",
    "B=torch.tensor([[7,10],\n",
    "               [8,11],\n",
    "               [9,12]], dtype=torch.float32)\n",
    "torch.matmul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ab135eb-55f1-419d-8537-47694167f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Transposing\n",
    "print(A)\n",
    "print(B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04e843c0-d340-4149-bfe3-f8854caec505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: A=torch.Size([3, 2]), B=torch.Size([3, 2])\n",
      "\n",
      "New shapes: A=torch.Size([3, 2]) (same), B=torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2])*torch.Size([2, 3]) <- the inner dimensions match!\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes: A={A.shape}, B={B.shape}\\n\")\n",
    "print(f\"New shapes: A={A.shape} (same), B={B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {A.shape}*{B.T.shape} <- the inner dimensions match!\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output=torch.matmul(A,B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b6d1637-9bd9-4b02-b7d6-147a807398e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(A,B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243c9cab-70c7-4dfb-b730-9f3e547a5ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

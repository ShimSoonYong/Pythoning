{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663b73ad-5c40-4d2f-9b70-12d6803ad921",
   "metadata": {},
   "source": [
    "### Importing PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bfb6cc-0238-4182-b627-aac4901b36fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2+cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc992f7d-c68b-465d-add2-b5f7feb504b1",
   "metadata": {},
   "source": [
    "# Introduction to tensors\n",
    "\n",
    "Tensors are the fundamental buidling block of machine learning.\n",
    "Their job is to represent data in a numerical way.\n",
    "\n",
    "EX: A tensor with shape [3, 224, 224] can be [color_channels, height, width], as in the image has 3 color channels(RGB), a height of 224 pixels and a width of 224 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403405aa-1a04-437c-98c2-455fca6dbde4",
   "metadata": {},
   "source": [
    "### Creating tensors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "385c69de-f0c5-44cb-9971-1d9f440f585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar\n",
    "scalar=torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d115911-7584-49f6-8df9-04d6672355f2",
   "metadata": {},
   "source": [
    "Chek the dimensions of a tensor using the ndim attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f36f5d-09bc-4f3f-bcfb-138fa62abec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e3ca2-9ae1-4cf9-b186-2ec917f4a594",
   "metadata": {},
   "source": [
    "Retrieve the number from the tensor using the item() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4250adda-ea7b-4d62-9372-d9d44710b23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b94b36a-90c6-4737-8a44-a09eea31032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector=torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006f319b-6228-45d8-b474-01172ab47648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d746e-d29f-4659-aef2-10a8e4845f91",
   "metadata": {},
   "source": [
    "Another important concept for tensors is their shape attribute. The shape tells you how the elements inside them are arranged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7689682-ce26-427b-afe2-783e9ac7ce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e8fbc-3b27-4865-9787-49024c6e6c48",
   "metadata": {},
   "source": [
    "This is because of the two elements we placed inside the square brackets([7, 7])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16ee370-5770-4e4d-91ef-78551daff7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX=torch.tensor([[7,8],\n",
    "                    [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc218c5e-757d-4480-a5ae-941cbb1d51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4596e30-39eb-47dc-ab2b-c7f9deffb707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbfe42a-9732-48ea-8bc7-48d02844f6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 4, 5]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR=torch.tensor([[[1,2,3],\n",
    "                      [3,6,9],\n",
    "                      [2,4,5]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3a2b6c0-c9dd-49a0-8175-b8f54dc81976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135c5758-6d31-453a-9810-2f4323a06aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fa14d-00b2-4b17-89b1-9615831dab98",
   "metadata": {},
   "source": [
    "# Random tensors\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2c34e56-ff58-4d19-a004-d55684763df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0582, 0.9371, 0.3672, 0.6569],\n",
       "         [0.2204, 0.1921, 0.8432, 0.8850],\n",
       "         [0.2315, 0.3196, 0.1026, 0.9369]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor=torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fddc12d8-aa93-4178-9f18-4c4a2f3f2a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor=torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e90f7-43a0-4ffb-917c-12ad93b273bb",
   "metadata": {},
   "source": [
    "# torch.zeros and torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9536cb4-255a-4d01-9b41-db1ea5571e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros=torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1818381-edaa-4326-8386-568e6c26e19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones=torch.ones(size=(3,4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e804e394-e415-4938-bca0-9c12bf128661",
   "metadata": {},
   "source": [
    "# Creating a range and tensors like\n",
    "You can use torch.arange(start, end, step) to do so.\n",
    "\n",
    "Note: In Python, you can use range() to create a range, by in PyTorch, torch.range() is deprecated and may show an error.future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a512b9c-b5af-41e7-97dc-96e7c5ac2a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17836\\709803459.py:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  zero_to_ten_deprecated=torch.range(0,10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_to_ten_deprecated=torch.range(0,10)\n",
    "\n",
    "zero_to_ten=torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fadc9-7728-4f36-ad6a-2296343459c2",
   "metadata": {},
   "source": [
    "To do so, you can use \n",
    "torch.zeros_like(input)\n",
    "or\n",
    "torch.ones_like(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f1e8758-0735-4548-ae63-e78268976700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros=torch.zeros_like(input=zero_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1640cd0c-18c0-4014-a304-4c90941cd7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones=torch.ones_like(input=ten_zeros)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2f2a4d-f6db-4780-8340-c2599810911c",
   "metadata": {},
   "source": [
    "# Tensor datatypes\n",
    "\n",
    "Lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluations metrics like accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e7c278c-7946-423a-8858-5d7e92791bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor=torch.tensor([3.0,6.0,9.0],\n",
    "                             dtype=None,\n",
    "                             device=None,\n",
    "                             requires_grad=False)\n",
    "float_32_tensor.shape, float_32_tensor.dtype,float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69206f3b-2b33-4f6b-b45b-4a991e404a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=torch.tensor([3.0,6.0,9.0],\n",
    "                             dtype=torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d318814-1914-409b-b91e-a33f971d2739",
   "metadata": {},
   "source": [
    "# Getting information from tensors\n",
    "shape, dtype, device are the most common attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f54769e-075e-4905-a039-7a7b95a2452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4791, 0.7172, 0.0697, 0.3434],\n",
      "        [0.0581, 0.6294, 0.7597, 0.2216],\n",
      "        [0.3723, 0.7616, 0.9845, 0.5932]])\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor=torch.rand(3,4)\n",
    "\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75feeea3-da4f-4d2a-9901-ecced4c74956",
   "metadata": {},
   "source": [
    "# Tensor operations\n",
    "\n",
    "Addition, Subtraction, Multiplication, Division, Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ced1ab1-76bc-4b33-9ade-f9e9a572a17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.tensor([1,2,3])\n",
    "tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9004de11-b080-497c-a08c-ed41703f5067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e59d4aa-e668-48fb-b73d-9425db23b036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afdab7d7-c7a8-4b51-affb-4c18be741ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=tensor-10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4acaf54-7ceb-4399-99d7-2f56b6de0698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=tensor+10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94299eda-61ef-45cc-bab9-e3e82fa1dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals to tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise muliplication\n",
    "print(tensor,\"*\",tensor)\n",
    "print(\"Equals to\",tensor*tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e7a58-a2b0-46e4-abd3-20409570d529",
   "metadata": {},
   "source": [
    "### Matrix multiplication( is all you need!)\n",
    "1. The inner dimensions must match\n",
    "2. The resulting matrix has the shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89386660-43f5-416a-beef-750bd87e7c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor=torch.tensor([1,2,3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4539f4a2-bf2c-47c3-95a9-7c09ed9af62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "print(tensor*tensor)\n",
    "print(tensor@tensor) # Not recommended\n",
    "print(torch.matmul(tensor,tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56561582-b4ed-45b7-9c85-def7d136c795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.17 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "value=0\n",
    "for i in range(len(tensor)):\n",
    "    value+=tensor[i]*tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "665835be-70a4-44ee-b554-fba858613ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9248f-c974-4764-af59-31bd00b96d24",
   "metadata": {},
   "source": [
    "#### One of the most common errors in deep learning (shape erros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e847ee3b-2b8c-4c87-b75a-082d08b2b4b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m A\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      2\u001b[0m                [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      3\u001b[0m                [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      4\u001b[0m B\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      5\u001b[0m                [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[0;32m      6\u001b[0m                [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m----> 7\u001b[0m torch\u001b[38;5;241m.\u001b[39mmatmul(A,B)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "A=torch.tensor([[1,2],\n",
    "               [3,4],\n",
    "               [5,6]], dtype=torch.float32)\n",
    "B=torch.tensor([[7,10],\n",
    "               [8,11],\n",
    "               [9,12]], dtype=torch.float32)\n",
    "torch.matmul(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ab135eb-55f1-419d-8537-47694167f4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# Transposing\n",
    "print(A)\n",
    "print(B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04e843c0-d340-4149-bfe3-f8854caec505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: A=torch.Size([3, 2]), B=torch.Size([3, 2])\n",
      "\n",
      "New shapes: A=torch.Size([3, 2]) (same), B=torch.Size([2, 3])\n",
      "\n",
      "Multiplying: torch.Size([3, 2])*torch.Size([2, 3]) <- the inner dimensions match!\n",
      "\n",
      "Output:\n",
      "\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes: A={A.shape}, B={B.shape}\\n\")\n",
    "print(f\"New shapes: A={A.shape} (same), B={B.T.shape}\\n\")\n",
    "print(f\"Multiplying: {A.shape}*{B.T.shape} <- the inner dimensions match!\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output=torch.matmul(A,B.T)\n",
    "print(output)\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6d1637-9bd9-4b02-b7d6-147a807398e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.,  30.,  33.],\n",
       "        [ 61.,  68.,  75.],\n",
       "        [ 95., 106., 117.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm is a shortcut for matmul\n",
    "torch.mm(A,B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b60e0-3d86-4cb5-8965-534572ef4037",
   "metadata": {},
   "source": [
    "The torch.nn.Linear() module is fully connected layer of PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "899dce66-0f13-4e7d-aafb-adecffe32909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output: \n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "linear=torch.nn.Linear(in_features=2,\n",
    "                       out_features=6)\n",
    "\n",
    "x=A\n",
    "output=linear(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output: \\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e1e5db-58a3-4c47-a702-da9713fd4af4",
   "metadata": {},
   "source": [
    "#### Remember, matrix multiplication is all you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2df293-a844-458b-afd5-2f55a883fb0e",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a678145-7a6b-48db-a69c-4863edc89b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a79e8d7-c30c-480c-99af-d0d110db1668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # Must be the float32 datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f70382c5-e369-4adb-b621-4b8698d1c260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96061a6-dfc5-4b38-93d1-fd5299f0d312",
   "metadata": {},
   "source": [
    "### Positional min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a67320e3-b6c6-47b7-bee3-c8d91fa2772b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.arange(10,100,10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3fc68-bcce-4346-aee3-16f493f0979d",
   "metadata": {},
   "source": [
    "## Change tensor datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47bc897b-02ff-4865-aa2c-a6917458b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.arange(10.,100.,10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63981cbe-000d-4cb1-bff5-b781fdf9aa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float16=tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b944bbd0-6c85-4af4-a581-c8690b5d1f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_int8=tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5687a4d-6896-421f-b56e-dd7170d2558a",
   "metadata": {},
   "source": [
    "# Reshaping, stacking, squeezing and unsqeezing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe45accb-0e6a-449f-9ce2-aa26c4ac85a5",
   "metadata": {},
   "source": [
    "To do so, some popular methods are:\n",
    "\n",
    "torch.reshape(input, shape)\tReshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "\n",
    "Tensor.view(shape)\tReturns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "\n",
    "torch.stack(tensors, dim=0)\tConcatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "\n",
    "torch.squeeze(input)\tSqueezes input to remove all the dimenions with value 1.\n",
    "\n",
    "torch.unsqueeze(input, dim)\tReturns input with a dimension value of 1 added at dim.\n",
    "\n",
    "torch.permute(input, dims)\tReturns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80873a49-f38a-4492-9b51-706a3184efb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(1.,8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c806abbd-ffd4-42cf-b209-71525edbb33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped=x.reshape(1,7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73972656-736d-481b-afa4-fb6a3b5d3264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view: keeps same data as original but changes view\n",
    "z=x.view(1,7)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57652009-6a18-4017-8607-dd3ac740b6b1",
   "metadata": {},
   "source": [
    "So changing the view changes the original tensor too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb58f75c-37a9-4003-befa-87a9fd47cf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0]=5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85f4e9b1-0a93-4485-9b42-d4412dae4dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.],\n",
       "         [5., 2., 3., 4., 5., 6., 7.]]),\n",
       " tensor([[5., 5., 5., 5.],\n",
       "         [2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3.],\n",
       "         [4., 4., 4., 4.],\n",
       "         [5., 5., 5., 5.],\n",
       "         [6., 6., 6., 6.],\n",
       "         [7., 7., 7., 7.]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked_first_dim=torch.stack([x,x,x,x], dim=0)\n",
    "x_stacked_second_dim=torch.stack([x,x,x,x], dim=1)\n",
    "x_stacked_first_dim, x_stacked_second_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b2f6d2-751e-4270-bf26-d37c328ee211",
   "metadata": {},
   "source": [
    "#### Squeezing tensor means make a vecotr from a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9e3da2b6-ecb4-432d-aab0-aa62199d37b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "Previous shape: torch.Size([1, 7])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "New shape: torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "x_squeezed=x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a22266e-cd5b-420f-9175-5feb82a5c146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
      "Previous shape: torch.Size([7])\n",
      "\n",
      "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
      "New shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "x_unsqueezed=x_squeezed.unsqueeze(dim=0) # Row-wise unsqueezing\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b86aacd1-eff1-40c2-9429-4ebcc64145f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x_original=torch.rand(size=(224,224,3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted=x_original.permute(2,0,1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d5930-9fc4-429d-a186-021f9f98733f",
   "metadata": {},
   "source": [
    "# Indexing (selecting data from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "07de25ef-84cf-4efb-8d0a-dd8e53679ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(1,10).reshape(1,3,3) # Num of matrices, num of vectors, num of scalars\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9ecf6-4bcf-4d7a-b059-fbb939dee769",
   "metadata": {},
   "source": [
    "### Indexing values goes outer dimension to inner dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24e3418a-076a-442f-80b0-1eddc85fee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First square bracket: \n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Second square bracket: tensor([1, 2, 3])\n",
      "Third square bracket: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"First square bracket: \\n{x[0]}\")\n",
    "print(f\"Second square bracket: {x[0][0]}\")\n",
    "print(f\"Third square bracket: {x[0][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af8865f2-a0aa-446d-bd8e-014ca93c372e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), tensor([[2, 5, 8]]), tensor([5]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0], x[:,:,1], x[:,1,1], x[0,0,:] # Scalar(0), Vector(1), Matrix(2),..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69cb6d-641c-418c-b3f4-12f8a6832d94",
   "metadata": {},
   "source": [
    "# PyTorch tensors & NumPy\n",
    "\n",
    "torch.from_numpy(ndarray) : NumPy array to PyTorch tensor.<br>\n",
    "torch.Tensor.numpy() : PyTorch tensor to NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fe46c870-4201-48bc-a603-af6a6ba93e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch;import numpy as np\n",
    "array=np.arange(1.0,8.0)\n",
    "tensor=torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95de4c40-bff7-4fe0-b73e-7472454bfc8e",
   "metadata": {},
   "source": [
    "***\n",
    "> Note: By default, NumPy arrays are created with the datatype torch.float64 and if you convert it to a PyTorch tensor, it'll keep the same datatype(as above).\n",
    "> However, many PyTorch caculations default to using torch.float32.\n",
    "> So if you want to convert your NumPy array to PyTorch tensor with torch.float32 datatype, you can use tensor=torch.fram_numpy(array).type(torch.float(32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9a4346b-892e-416d-9e6b-6018fe50795b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array=array+1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6be4768-866a-4c3a-9e23-0fe2211b45ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.ones(7)\n",
    "numpy_tensor=tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "c789981c-9a7e-4505-9382-245465e83ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([306., 306., 306., 306., 306., 306., 306.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor+=1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5589c81-c2f4-4156-8a13-0db33fc22e80",
   "metadata": {},
   "source": [
    "# Reproducibility (reliable randomized result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f1d05c9f-4c5a-421e-8985-91046bf90ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A:\n",
      "tensor([[0.4563, 0.9719, 0.3968, 0.1496],\n",
      "        [0.4743, 0.9973, 0.4436, 0.9726],\n",
      "        [0.5194, 0.5337, 0.7050, 0.3362]])\n",
      "\n",
      "Tensor B:\n",
      "tensor([[0.7891, 0.1694, 0.1800, 0.7177],\n",
      "        [0.6988, 0.5510, 0.2485, 0.8518],\n",
      "        [0.0963, 0.1338, 0.2741, 0.6142]])\n",
      "\n",
      "Does Tensor A equal Tensor B? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "random_tensor_A=torch.rand(3,4)\n",
    "random_tensor_B=torch.rand(3,4)\n",
    "\n",
    "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
    "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
    "print(\"Does Tensor A equal Tensor B? (anywhere)\")\n",
    "random_tensor_A==random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "42fd25ae-6daa-4339-aa2b-890a406f6ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor C:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Tensor D:\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "\n",
      "Does Tensor C equal Tensor D? (anywhere)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C=torch.rand(3,4)\n",
    "\n",
    "torch.random.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_D=torch.rand(3,4)\n",
    "\n",
    "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
    "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
    "print(\"Does Tensor C equal Tensor D? (anywhere)\")\n",
    "random_tensor_C==random_tensor_D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b969ab-0de8-4614-8c6c-5e8a3eb31c90",
   "metadata": {},
   "source": [
    "# Running tensors on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "a8deb227-6d66-4f60-aa1c-ac2a4adff95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'nvidia-smi'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\", '배치 파일이 아닙니다.']"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!nvidia-smi # Checking NVIDIA GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "aecbb46f-513e-43e3-8821-19cec15dcb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ec3025e0-47ed-4495-bd6c-ffc7ff4f2b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "2c23d209-431b-4006-bb86-16d59fa3bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8e42b4-7950-4e3c-91fa-7b6877186236",
   "metadata": {},
   "source": [
    "# Moving tensors back to the CPU\n",
    "All codes are just examples, so error code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "82c9bd54-afa1-4444-a006-9c0b9f248193",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_on_gpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[435], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy (this will error)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tensor_on_gpu\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor_on_gpu' is not defined"
     ]
    }
   ],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "7f69d6d0-f919-441c-888b-a2db92fe926b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensor_on_gpu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[436], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Instead, copy the tensor back to cpu\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tensor_back_on_cpu \u001b[38;5;241m=\u001b[39m tensor_on_gpu\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m tensor_back_on_cpu\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensor_on_gpu' is not defined"
     ]
    }
   ],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
